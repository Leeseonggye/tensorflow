{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF3-horses-or-humans-type-B_시험용",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leeseonggye/tensorflow/blob/main/TF3_horses_or_humans_type_B_%EC%8B%9C%ED%97%98%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpNdRzQH6Mo7"
      },
      "source": [
        "# Question\n",
        "#\n",
        "# This task requires you to create a classifier for horses or humans using\n",
        "# the provided data. Please make sure your final layer is a 1 neuron, activated by sigmoid as shown.\n",
        "# Please note that the test will use images that are 300x300 with 3 bytes color depth so be sure to design your neural network accordingly\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 3 - Horses Or Humans (Type B)\n",
        "# val_loss: 0.51 (더 낮아도 안 좋고, 높아도 안 좋음!)\n",
        "# val_acc: 관계없음\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def solution_model():\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "    local_zip = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/horse-or-human/')\n",
        "    zip_ref.close()\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "    local_zip = 'validation-horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(#Your Code here)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # Note the input shape specified on your first layer must be (300,300,3)\n",
        "        # Your Code here\n",
        "\n",
        "        # This is the last layer. You should not change this code.\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(#Your Code Here#)\n",
        "\n",
        "    model.fit(#Your Code Here#)\n",
        "\n",
        "    # NOTE: If training is taking a very long time, you should consider setting the batch size appropriately on the generator, and the steps per epoch in the model.fit#\n",
        "    return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-horses-or-humans-type-B.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0t1HZEX5W-S"
      },
      "source": [
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT1pxF0C5XIy"
      },
      "source": [
        "_TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "_TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "local_zip = 'horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/horse-or-human/')\n",
        "zip_ref.close()\n",
        "urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "local_zip = 'validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnIOrpaY5XM6"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale= 1/255,\n",
        "                                   horizontal\n",
        "                                   )\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(#Your Code here)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        #Your Code Here)\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        #Your Code Here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRcnz5ze7lHq"
      },
      "source": [
        "TRAIN_DIR = 'tmp/horse-or-human/'\n",
        "VALID_DIR = 'tmp/validation-horse-or-human/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q9gZzBH5XPP"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.0, \n",
        "                                   rotation_range = 0.3,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.3,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkRQpjuq7NV4",
        "outputId": "1e6ffae5-aa0b-4676-ed79-270a0d0e5529"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size= (300,300),\n",
        "                                                    class_mode = 'binary')\n",
        "valid_generator = validation_datagen.flow_from_directory(VALID_DIR, target_size= (300,300),\n",
        "                                                    class_mode = 'binary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0i_7TAy8IOy"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        Conv2D(128, (3,3), input_shape = (300,300,3), activation= 'relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Conv2D(64, (3,3), activation= 'relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Conv2D(32, (3,3), activation= 'relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Conv2D(16, (3,3), activation= 'relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Flatten(),\n",
        "        Dense(512, activation= 'relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FXOon5F8u-I",
        "outputId": "049db229-6486-415f-dc23-8c4ca83e7ed7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 298, 298, 128)     3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 149, 149, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 147, 147, 64)      73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 73, 73, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 71, 71, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 35, 35, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 33, 33, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 2,198,641\n",
            "Trainable params: 2,198,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW-hyuXr80tV"
      },
      "source": [
        "checkpoint_path = 'mycheckpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, verbose = 1,\n",
        "                             save_best_only = True, save_weights_only = True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyU_4urX9Bo9"
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xOWR8lO9JL8",
        "outputId": "b975603f-5947-4a58-c87d-f6b78c43f0a9"
      },
      "source": [
        "model.fit(train_generator, validation_data=valid_generator, epochs = 25,\n",
        "          callbacks = [checkpoint],\n",
        "          steps_per_epoch = len(train_generator), validation_steps = len(valid_generator),\n",
        "          verbose = 1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "33/33 [==============================] - 36s 953ms/step - loss: 0.6927 - acc: 0.5823 - val_loss: 1.7560 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.75598, saving model to mycheckpoint.ckpt\n",
            "Epoch 2/25\n",
            "33/33 [==============================] - 32s 958ms/step - loss: 0.6693 - acc: 0.5891 - val_loss: 0.5148 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.75598 to 0.51484, saving model to mycheckpoint.ckpt\n",
            "Epoch 3/25\n",
            "33/33 [==============================] - 32s 958ms/step - loss: 0.5789 - acc: 0.6904 - val_loss: 0.8117 - val_acc: 0.6992\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.51484\n",
            "Epoch 4/25\n",
            "33/33 [==============================] - 32s 965ms/step - loss: 0.4720 - acc: 0.7897 - val_loss: 0.8462 - val_acc: 0.6211\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.51484\n",
            "Epoch 5/25\n",
            "33/33 [==============================] - 32s 970ms/step - loss: 0.4640 - acc: 0.7790 - val_loss: 0.8600 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.51484\n",
            "Epoch 6/25\n",
            "33/33 [==============================] - 32s 965ms/step - loss: 0.3729 - acc: 0.8335 - val_loss: 1.0904 - val_acc: 0.7109\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.51484\n",
            "Epoch 7/25\n",
            "33/33 [==============================] - 32s 965ms/step - loss: 0.3288 - acc: 0.8588 - val_loss: 2.9150 - val_acc: 0.5781\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.51484\n",
            "Epoch 8/25\n",
            "33/33 [==============================] - 32s 965ms/step - loss: 0.3067 - acc: 0.8676 - val_loss: 0.9367 - val_acc: 0.7383\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.51484\n",
            "Epoch 9/25\n",
            "33/33 [==============================] - 32s 961ms/step - loss: 0.2303 - acc: 0.9056 - val_loss: 0.9178 - val_acc: 0.7695\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.51484\n",
            "Epoch 10/25\n",
            "33/33 [==============================] - 32s 965ms/step - loss: 0.2158 - acc: 0.9231 - val_loss: 1.4501 - val_acc: 0.6953\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.51484\n",
            "Epoch 11/25\n",
            "33/33 [==============================] - 32s 965ms/step - loss: 0.2565 - acc: 0.9017 - val_loss: 1.2876 - val_acc: 0.6836\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.51484\n",
            "Epoch 12/25\n",
            "33/33 [==============================] - 32s 964ms/step - loss: 0.1785 - acc: 0.9377 - val_loss: 0.6680 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.51484\n",
            "Epoch 13/25\n",
            "33/33 [==============================] - 32s 959ms/step - loss: 0.1861 - acc: 0.9348 - val_loss: 1.9347 - val_acc: 0.6484\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.51484\n",
            "Epoch 14/25\n",
            "33/33 [==============================] - 32s 951ms/step - loss: 0.2266 - acc: 0.9143 - val_loss: 0.8227 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.51484\n",
            "Epoch 15/25\n",
            "33/33 [==============================] - 32s 963ms/step - loss: 0.1371 - acc: 0.9533 - val_loss: 1.6375 - val_acc: 0.6797\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.51484\n",
            "Epoch 16/25\n",
            "33/33 [==============================] - 32s 959ms/step - loss: 0.1176 - acc: 0.9591 - val_loss: 1.7641 - val_acc: 0.7422\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.51484\n",
            "Epoch 17/25\n",
            "33/33 [==============================] - 32s 960ms/step - loss: 0.1060 - acc: 0.9649 - val_loss: 1.1763 - val_acc: 0.7891\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.51484\n",
            "Epoch 18/25\n",
            "33/33 [==============================] - 32s 954ms/step - loss: 0.0975 - acc: 0.9669 - val_loss: 0.6401 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.51484\n",
            "Epoch 19/25\n",
            "33/33 [==============================] - 32s 955ms/step - loss: 0.1061 - acc: 0.9552 - val_loss: 1.8591 - val_acc: 0.7383\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.51484\n",
            "Epoch 20/25\n",
            "33/33 [==============================] - 32s 962ms/step - loss: 0.0944 - acc: 0.9630 - val_loss: 1.5094 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.51484\n",
            "Epoch 21/25\n",
            "33/33 [==============================] - 32s 960ms/step - loss: 0.0642 - acc: 0.9776 - val_loss: 1.5422 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.51484\n",
            "Epoch 22/25\n",
            "33/33 [==============================] - 32s 954ms/step - loss: 0.0982 - acc: 0.9708 - val_loss: 1.4067 - val_acc: 0.7617\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.51484\n",
            "Epoch 23/25\n",
            "33/33 [==============================] - 32s 951ms/step - loss: 0.0781 - acc: 0.9718 - val_loss: 1.9985 - val_acc: 0.7539\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.51484\n",
            "Epoch 24/25\n",
            "33/33 [==============================] - 31s 947ms/step - loss: 0.0686 - acc: 0.9747 - val_loss: 1.7844 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.51484\n",
            "Epoch 25/25\n",
            "33/33 [==============================] - 32s 951ms/step - loss: 0.0656 - acc: 0.9786 - val_loss: 1.2772 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.51484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd88ec20250>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqvSv-PK9dDm",
        "outputId": "be6d8742-c143-4e90-9dc1-2c4274fd8e5a"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd937c2a090>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeFOFvgUECkV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}